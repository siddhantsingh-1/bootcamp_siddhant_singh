{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcfd2b9e-b998-40e0-ab1d-9e96110671b3",
   "metadata": {},
   "source": [
    "#HW 5 \n",
    "To save/load CSV and Parquet with environment-driven paths, organize data/raw/ vs data/processed/, and document storage choices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441f6742-3e40-4ecc-a97d-9bb8b91becc3",
   "metadata": {},
   "source": [
    "Name: Dhairya Gouchwal \n",
    "\n",
    "Date: 19th August 2025\n",
    "\n",
    "Objectives:\n",
    "- Env-driven paths to `data/raw/` and `data/processed/`\n",
    "- Save CSV and Parquet; reload and validate\n",
    "- Abstract IO with utility functions; document choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bace7c8d-d023-404b-876a-1227cf6f581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45f5ea0d-918a-403f-bebb-150bb1093793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/raw , data/processed\n"
     ]
    }
   ],
   "source": [
    "# Step 1\n",
    "dotenv_path = \"../.env\"\n",
    "load_dotenv(dotenv_path)\n",
    "DATA_DIR_RAW = os.getenv(\"DATA_DIR_RAW\")\n",
    "DATA_DIR_PROCESSED = os.getenv(\"DATA_DIR_PROCESSED\")\n",
    "print (DATA_DIR_RAW,\",\", DATA_DIR_PROCESSED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "155d4e09-9efa-4c8b-9761-de2da1c8ef7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastparquet in c:\\users\\dhair\\anaconda3\\envs\\fe-course\\lib\\site-packages (2024.11.0)\n",
      "Requirement already satisfied: pandas>=1.5.0 in c:\\users\\dhair\\anaconda3\\envs\\fe-course\\lib\\site-packages (from fastparquet) (2.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\dhair\\anaconda3\\envs\\fe-course\\lib\\site-packages (from fastparquet) (2.3.2)\n",
      "Requirement already satisfied: cramjam>=2.3 in c:\\users\\dhair\\anaconda3\\envs\\fe-course\\lib\\site-packages (from fastparquet) (2.11.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\dhair\\anaconda3\\envs\\fe-course\\lib\\site-packages (from fastparquet) (2025.7.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\dhair\\anaconda3\\envs\\fe-course\\lib\\site-packages (from fastparquet) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dhair\\anaconda3\\envs\\fe-course\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dhair\\anaconda3\\envs\\fe-course\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dhair\\anaconda3\\envs\\fe-course\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dhair\\anaconda3\\envs\\fe-course\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab1664f5-2eb8-4785-a6ba-0e968dd0c8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"Name\": [\"A\", \"B\", \"C\"],\n",
    "    \"Roll No.\": [1,2,3],\n",
    "    \"Class Taken\" : [\"Math\", \"English\", \"Science\"]\n",
    "})\n",
    "\n",
    "csv_path = os.path.join(r\"C:\\Users\\dhair\\bootcamp_dhairya_gouchwal\\homework\\homework5\\data\\raw\", \"sample.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "19b12694-460e-4587-af5f-178769f77831",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_path = os.path.join(r\"C:\\Users\\dhair\\bootcamp_dhairya_gouchwal\\homework\\homework5\\data\\processed\", \"sample.parquet\")\n",
    "df.to_parquet(parquet_path, engine=\"fastparquet\", index =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4049d8d5-6ccd-4b24-81f9-4f5ec90954b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV shape: (3, 3)\n",
      "Parquet shape: (3, 3)\n",
      "{'same_shape': True, 'same_dtypes': True}\n"
     ]
    }
   ],
   "source": [
    "# Step 2 Validate and reload\n",
    "\n",
    "df_csv = pd.read_csv(csv_path)\n",
    "df_parquet = pd.read_parquet(parquet_path, engine=\"fastparquet\", index =False)\n",
    "\n",
    "print(\"CSV shape:\", df_csv.shape)\n",
    "print(\"Parquet shape:\", df_parquet.shape)\n",
    "\n",
    "def validate_df(df1, df2, key_cols):\n",
    "    same_shape = df1.shape == df2.shape\n",
    "    same_dtypes = all(df1[c].dtype == df2[c].dtype for c in key_cols)\n",
    "    return {\"same_shape\": same_shape, \"same_dtypes\": same_dtypes}\n",
    "\n",
    "results = validate_df(df_csv, df_parquet, key_cols=[\"Roll No.\", \"Class Taken\"])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1319a4ae-6393-4fc4-8af5-4ddd70f93363",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3 Utilities\n",
    "def write_df(df, path, **kwargs):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    if path.endswith(\".csv\"):\n",
    "        df.to_csv(path, index=False, **kwargs)\n",
    "    elif path.endswith(\".parquet\"):\n",
    "        try:\n",
    "            df.to_parquet(path, index=False, **kwargs)\n",
    "        except ImportError:\n",
    "            raise RuntimeError(\"Missing Parquet engine. Install pyarrow or fastparquet.\")\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Use .csv or .parquet\")\n",
    "\n",
    "def read_df(path, **kwargs):\n",
    "    if path.endswith(\".csv\"):\n",
    "        return pd.read_csv(path, **kwargs)\n",
    "    elif path.endswith(\".parquet\"):\n",
    "        return pd.read_parquet(path, **kwargs)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Use .csv or .parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d925a0fc-0dec-496d-b527-98ecf32dcb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV shape: (3, 3)\n",
      "Parquet shape: (3, 3)\n"
     ]
    }
   ],
   "source": [
    "# Demo - using utitlites\n",
    "write_df(df, csv_path)\n",
    "write_df(df, parquet_path, engine = \"fastparquet\")\n",
    "\n",
    "df_csv = read_df(csv_path)\n",
    "df_parquet = read_df(parquet_path, engine = \"fastparquet\")\n",
    "\n",
    "print(\"CSV shape:\", df_csv.shape)\n",
    "print(\"Parquet shape:\", df_parquet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac960a89-cb3f-4c6e-94e4-e19a3aef7b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
